## Цель работы:
Научиться предсказывать отток клиентов по имеющимся данным.   

Главной задачей проекта было построить модель, которая на основании предоставленных данных смогла бы предсказывать отток клиентов. Для выполнения данной задачи был составлен план, где было описано три основных этапа работ: исследовательский анализ данных, прдобработка данных и построение моделей.


1.
     Первый этап представлял собой первичный осмотр данных, где были осмотрены распределения прихнаков четырех датасетов, оценен дисбаланс классов, проверено наличие явных дубликатов. Выполнение первого этапа не вызвало трудностей и прошло согласно плану.

2.
    На втором этапе требовалось преобразовать данные в подходязий для модели вид. Сначала трбеовалось соединить все таблицы в один датафрейм. После выполнения данной операции, в датафрейме появились пропуски, которые были заполнены соответствующими контексту признака значениями. Затем был создан целевой признак и признак Days с длительностью пользования услугами компании в днях,  для чего пришлось привести тип данных признаков с датами к datetype.
    >
     Были удалены признаки, не несущие информации в контексте данной задачи: 'customerID', 'BeginDate', 'EndDate'. Далее была проведена повторная оценка распределения признаков. Затем, для ускорения дальнейшего процесса обучения модели, была построена матрица корелляции признаков. Признаки с наибольшими коэффициентом корелляции - а именно 'gender','InternetService','StreamingMovies', 'PaperlessBilling', 'OnlineSecurity','StreamingTV'- были удалены.
    >
     Финальный датафрейм содержал следующие признаки: 'Type', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges','OnlineBackup', 'DeviceProtection', 'TechSupport', 'MultipleLines', 'SeniorCitizen', 'Partner', 'Dependents', 'HasLeft', 'BeginYear'.
    >
     Далее данные были поделены на тренировочную и тестовую выборки в соотношении 1/3, были выделены матрицы признаков и векторы меток классов. Затем были созданы два кодировщика - OneHotEncoder и OrdinalEncoder, и, посредством кодирования исходного датасета X_train, два новых датасета: X_train_ohe и X_train_oe, для обучения линейных и нелинейных моделей соответственно. Для стандартизации непрерывных признаков был создан стандартизатор StandardScaler, который применился на двух полученных датасетах.
    >
     В процессе выполнения данного этапа возникли трудностей не возникло.

3.
     На третьем этапе было построено три модели: CatboostRegressor, RandomForest LogisticRegression, подбор параметров для которых был осуществлен с помощью Random Search.

     На данном этапе возникли затруднения при обучении модели: значение метрики на валидационной выборке было меньше порогового. Эта проблема решилась путем создания нового признака и удалением мультиколлинеарных признаков с помощью матрицы ошибок.


     Моделью с наилучшей метрикой оказался CatBoostClassifier с параметрами:
     {'learning_rate': 0.7000000000000001,
 'l2_leaf_reg': 1,
 'iterations': 140,
 'depth': 3}